{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Evaluating Logistic Regression on the [SPECTF Heart Data Set](https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart) and the [Skin Segmentation Data Set](https://archive.ics.uci.edu/ml/datasets/Skin+Segmentation). Using numpy, pandas and scikit-learn.\n",
    "\n",
    "## 1. Setup\n",
    "Imports the required dependencies, and define the path to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the datasets\n",
    "path = '../core/src/test/resources/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SPECTF Heart Data Set\n",
    "\n",
    "Prepare the training and testing dataset and convert them into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(path + 'spectf.train.csv')\n",
    "test_csv = pd.read_csv(path + 'spectf.test.csv')\n",
    "\n",
    "train_data = np.array(train_csv)\n",
    "X_train = train_data[:, 1:]\n",
    "y_train = np.ravel(train_data[:, 0])\n",
    "\n",
    "test_data = np.array(test_csv)\n",
    "X_test = test_data[:, 1:]\n",
    "y_test = np.ravel(test_data[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97468354430379744"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1, fit_intercept)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on the training dataset\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618279569892\n",
      "[[  7   8]\n",
      " [ 63 108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.10      0.47      0.16        15\n",
      "          1       0.93      0.63      0.75       171\n",
      "\n",
      "avg / total       0.86      0.62      0.71       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Check accuracy on the testing dataset\n",
    "print metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "print metrics.confusion_matrix(y_test, preds)\n",
    "print metrics.classification_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
